# **Predictive CI/CD Pipeline Optimizer**

A complete simulation of an AIOps-powered CI system that predicts build failures *before* running expensive test suites.
The project trains a machine learning model on historical build data and uses it to make real-time predictions for new commits.

---

## Project Structure

| File                        | Description                                                                                      |
| --------------------------- | ------------------------------------------------------------------------------------------------ |
| **`gui_app.py`**            | *(New)* Graphical dashboard for interactive predictions.                                         |
| **`generate_data.py`**      | Generates a simulated `build_history.csv` dataset with realistic commit patterns.                |
| **`train_model.py`**        | Trains a `RandomForestClassifier` and outputs `ci_model.pkl` and `model_features.json`.          |
| **`run_ci_pipeline.py`**    | Simulates a real CI inference step using commit metadata.                                        |
| **`visualize_analysis.py`** | Produces diagnostic charts (feature importance, confusion matrix, etc.) in the `images/` folder. |
| **`requirements.txt`**      | Python dependencies.                                                                             |

---

##  How to Run This Demo

### 1. **Set Up the Environment**

#### Create a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate
```

#### Install dependencies

```bash
pip install -r requirements.txt
```

---

### 2. **Generate Historical Data**

Creates `build_history.csv` with simulated CI build logs.

```bash
python generate_data.py
```

---

### 3. **Train the Machine Learning Model**

Reads the CSV and outputs:

* `ci_model.pkl`
* `model_features.json`

```bash
python train_model.py
```

You’ll see accuracy metrics and a classification report.

---

### 4. **Visualize the Model (Optional)**

Generates charts explaining model behavior.

```bash
python visualize_analysis.py
```

Output: PNG charts stored in `images/`.

---

### 5. **Launch the Prediction Dashboard (GUI)**

Interactive interface to test CI predictions.

```bash
python gui_app.py
```

#### Example Scenarios

* **Safe** → `main_dev`, `.py`, few changes → *GREEN*
* **Risky** → `new_dev`, `.yml`, many changes → *RED*

---

##  How to Integrate This Into a Real CI/CD System

This project models a real AIOps architecture.
Below is the recommended 3-phase approach.

---

## **Phase 1: Data Collection (Async Logging)**

Continuously collect build metadata into a shared datastore.

* **Database Options**: PostgreSQL, S3, DynamoDB, etc.
* **Add a CI Step (post-tests)** to log:

  * Commit author (`git log -1 --pretty=format:'%an'`)
  * File change summary (`git diff --shortstat`)
  * Build status (pass/fail)
* Send this data to your central database using a small Python script.

---

## **Phase 2: Scheduled Model Training**

Retrain the model regularly to learn from new build logs.

* **Scheduled job** (cron, GitHub Actions, Jenkins timer)
* Task flow:

  1. Read data from the central database.
  2. Retrain the model.
  3. Save `ci_model.pkl` and `model_features.json` to a shared location:

     * S3 bucket
     * GitHub Packages
     * Artifact store

---

## **Phase 3: Real-Time Prediction During CI**

Add a **pre-test step** to your CI pipeline:

1. Download the latest model artifacts.
2. Collect commit metadata for the new build.
3. Run:

   ```bash
   python run_ci_pipeline.py --args ...
   ```

### Smart Logic

`run_ci_pipeline.py` exits with:

* **0** → Prediction: *safe* → continue with long tests
* **1** → Prediction: *likely failure* → stop pipeline immediately

This structure cleanly separates:

* Data collection
* Automated training
* Real-time inference

…which aligns with MLOps best practices for robust AIOps deployment.
